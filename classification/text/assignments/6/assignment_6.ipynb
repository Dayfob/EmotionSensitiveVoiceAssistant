{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1b965007ac63be",
   "metadata": {},
   "source": [
    "# Statistical Machine Learnings\n",
    "\n",
    "Author: Alikhan Semembayev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88899e47ce03188c",
   "metadata": {},
   "source": [
    "## 1. Perform necessary data preprocessing, e.g. removing punctuation and stop words, stemming, lemmatizing. You may use the outputs from previous weekly assignments. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import demoji\n",
    "import svgling\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from autocorrect import Speller\n",
    "import re\n",
    "\n",
    "# Initialize tools\n",
    "spell = Speller()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "email_re = r\"\\b[A-Za-z]+@\\S+\\b\"\n",
    "ssn_re = r\"\\b[0-9]{3}-[0-9]{2}-[0-9]{4}\\b\"\n",
    "ip_re = r\"\\b\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}\\b\"\n",
    "\n",
    "street_number_re = r\"^\\d{1,}\"\n",
    "street_name_re = r\"[a-zA-Z0-9\\s]+,?\"\n",
    "city_name_re = r\" [a-zA-Z]+(\\,)?\"\n",
    "state_abbrev_re = r\" [A-Z]{2}\"\n",
    "postal_code_re = r\" [0-9]{5}$\"\n",
    "address_pattern_re = r\"\" + street_number_re + street_name_re + city_name_re + state_abbrev_re + postal_code_re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace emojis\n",
    "    text = demoji.replace(text)\n",
    "\n",
    "    # Remove smart quotes and dashes\n",
    "    text = text.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\").replace(\"-\", \" \").replace(\"'\", \" \")\n",
    "\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "    # print(words)\n",
    "\n",
    "    # Spelling correction + replace all t with not\n",
    "    words = ['not' if word == 't' else (\n",
    "        'ADDRESS' if re.match(address_pattern_re, word)\n",
    "        else (\n",
    "            'EMAIL' if re.match(email_re, word)\n",
    "            else (\n",
    "                'SSN' if re.match(ssn_re, word)\n",
    "                else (\n",
    "                    'IP' if re.match(ip_re, word)\n",
    "                    else spell(word)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ) for word in words]\n",
    "\n",
    "    # Remove stop words and non-alphabetic tokens and punctuation\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words or word in ['not', 'no']]\n",
    "\n",
    "    # POS tagging and Lemmatization\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    tag_map = defaultdict(lambda: \"n\")\n",
    "    tag_map[\"N\"] = \"n\"\n",
    "    tag_map[\"V\"] = \"v\"\n",
    "    tag_map[\"J\"] = \"a\"\n",
    "    tag_map[\"R\"] = \"r\"\n",
    "\n",
    "    words = [lemmatizer.lemmatize(word, pos=tag_map[tag[0]]) for word, tag in tagged_words]\n",
    "\n",
    "    # Return cleaned words as a single string\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6490ecee3808775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = (pd.read_csv('../../../../data/text/combined_raw.csv'))\n",
    "data = data.dropna(how='any')\n",
    "\n",
    "for row in data.values:\n",
    "    row[0] = clean_text(row[0])\n",
    "\n",
    "data.to_csv('../../../../data/text/combined_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29dab731d473b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:09:54.619821Z",
     "start_time": "2024-10-22T22:09:53.213324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text    emotion\n",
      "0  freshwater fish drink water skin via osmosis s...      happy\n",
      "1  think everyone must use daily become grained e...    neutral\n",
      "2  agree google headquarters mountain view califo...    neutral\n",
      "3  thats funny current ceo sunday ficha didnt kno...    neutral\n",
      "4  oh yeah not know either also want go google al...  surprised\n",
      "5                                                say  surprised\n",
      "6        yeah apparently lol instead hire people row      happy\n",
      "7  thats funny guess imaginative leave huge tech ...  surprised\n",
      "8  yeah exactly sure cheap one thing bet not expl...  surprised\n",
      "9  remember hearing immortality waste jellyfish h...    neutral\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = (pd.read_csv('../../../../data/text/combined_cleaned.csv'))\n",
    "data = data.dropna(how='any')\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46ca881e7f63fd",
   "metadata": {},
   "source": [
    "## 2. Propose a binary classification problem from your project data and identify the columns that you will use to solve the problem. You may need to create new columns of data. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf9fcc235da5670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:25:20.787113Z",
     "start_time": "2024-10-22T22:25:20.669250Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = (pd.read_csv('../../../../data/text/combined_cleaned.csv'))\n",
    "data = data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9612fc1c3a50385b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:25:29.467996Z",
     "start_time": "2024-10-22T22:25:29.116739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_happy</th>\n",
       "      <th>is_surprised</th>\n",
       "      <th>is_neutral</th>\n",
       "      <th>is_sad</th>\n",
       "      <th>is_fear</th>\n",
       "      <th>is_angry</th>\n",
       "      <th>is_disgust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>freshwater fish drink water skin via osmosis s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>think everyone must use daily become grained e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agree google headquarters mountain view califo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thats funny current ceo sunday ficha didnt kno...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh yeah not know either also want go google al...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_happy  is_surprised  \\\n",
       "0  freshwater fish drink water skin via osmosis s...         1             0   \n",
       "1  think everyone must use daily become grained e...         0             0   \n",
       "2  agree google headquarters mountain view califo...         0             0   \n",
       "3  thats funny current ceo sunday ficha didnt kno...         0             0   \n",
       "4  oh yeah not know either also want go google al...         0             1   \n",
       "\n",
       "   is_neutral  is_sad  is_fear  is_angry  is_disgust  \n",
       "0           0       0        0         0           0  \n",
       "1           1       0        0         0           0  \n",
       "2           1       0        0         0           0  \n",
       "3           1       0        0         0           0  \n",
       "4           0       0        0         0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = ['happy', 'surprised', 'neutral', 'sad', 'fear', 'angry', 'disgust']\n",
    "\n",
    "for emotion in emotions:\n",
    "    data[f'is_{emotion}'] = data['emotion'].apply(lambda x: 1 if x == emotion else 0)\n",
    "\n",
    "data = data.drop(columns=['emotion'])\n",
    "\n",
    "data.to_csv('../../../../data/text/combined_cleaned_multilabel.csv', index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1990c54c2c035c",
   "metadata": {},
   "source": [
    "## 3. Compute TF-IDF vectors on the text data.  (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b766d07971677f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:28:12.457263Z",
     "start_time": "2024-10-22T22:28:12.284686Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = (pd.read_csv('../../../../data/text/combined_cleaned_multilabel.csv'))\n",
    "data = data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e3ca98df2ce036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:30:00.130688Z",
     "start_time": "2024-10-22T22:29:56.610936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147380, 32085)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "print(X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f4f5fa68ae994",
   "metadata": {},
   "source": [
    "## 4. Solve your binary classification problem with the Naïve Bayes classifier.  (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "755a1d49f262cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:55:03.685508Z",
     "start_time": "2024-10-22T22:55:03.634888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7338512688288777\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84     20896\n",
      "           1       0.72      0.14      0.23      8580\n",
      "\n",
      "    accuracy                           0.73     29476\n",
      "   macro avg       0.73      0.56      0.54     29476\n",
      "weighted avg       0.73      0.73      0.66     29476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define features and labels\n",
    "X = X_tfidf\n",
    "y = data['is_happy']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c8d8ee59c6a1b",
   "metadata": {},
   "source": [
    "## 5. Solve your binary classification problem with the SVC classifier.  (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1af494e98ef98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T23:18:52.490670Z",
     "start_time": "2024-10-22T22:59:58.432249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.7476591124983037\n",
      "SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84     20896\n",
      "           1       0.71      0.23      0.34      8580\n",
      "\n",
      "    accuracy                           0.75     29476\n",
      "   macro avg       0.73      0.59      0.59     29476\n",
      "weighted avg       0.74      0.75      0.70     29476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the SVC classifier\n",
    "svc_classifier = SVC(kernel='linear')\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svc = svc_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"SVC Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
    "print(\"SVC Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6558c157aea0b1d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T23:20:32.197949Z",
     "start_time": "2024-10-22T23:20:32.192336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20089   807]\n",
      " [ 6631  1949]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_svc, normalize=None)\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
